P8105 Data Science I Homework 3
================
Olivia Wang (hw2852)
2022-10-15

In preparation for the problems below, we will load the following
libraries:

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(dplyr)
library(patchwork)
```

# Problem 1

This problem uses the `Instacart` data. This data set will be loaded
through the `p8105.datasets` library.

``` r
library(p8105.datasets)
data("instacart")
```

## 1.1 Description of `Instacart` Data

The `instacart` data set contains **1384617 rows** and **15 columns**.
Each row in the data set corresponds to a single item of an Instacart
order. The variables in the data set include ID numbers corresponding to
orders, products, and Instacart users, as well as the order in which a
particular product was added to cart. The data set contains a number of
order-level variables that describe the date and time an order was made,
and the number of days since a previous order was made. There are also
several item-specific variables that describe the product name,
department to which the product belongs, the aisle in which the product
can be found, and relevant order history.

There are **39123 products** found in **131209 orders** from **131209
distinct users**.

## 1.2 Analysis of `Instacart` Data

### Enumerating Total Aisles

We can enumerate the number of aisles by applying the `group_by`
function to identify the number of unique `aisle_id` variable values.
The number of rows generated in the output would be the number of aisles
in the data set. Building upon the results generated from the `group_by`
function, we may determine the aisles from which the most items were
ordered. This process involves generating a summary of the number of
times each `aisle_id` appears in these data, then arranging the aisles
in decreasing order of the number of times it appears.

``` r
instacart %>%
  group_by(aisle_id) %>% 
  summarise(items_ordered = n()) %>% 
  arrange(desc(items_ordered))
```

    ## # A tibble: 134 × 2
    ##    aisle_id items_ordered
    ##       <int>         <int>
    ##  1       83        150609
    ##  2       24        150473
    ##  3      123         78493
    ##  4      120         55240
    ##  5       21         41699
    ##  6      115         36617
    ##  7       84         32644
    ##  8      107         31269
    ##  9       91         26240
    ## 10      112         23635
    ## # … with 124 more rows

There are **134 aisles** in the `Instacart` data set. Of the 134 aisles,
the following are the aisles from which the most items are ordered:

| Aisle Number | Number of Items Sold |
|:-------------|----------------------|
| **83**       | 150,609              |
| **24**       | 150,473              |
| **123**      | 78,493               |
| **120**      | 55,240               |
| **21**       | 41,699               |

### Plotting Aisle vs. Items Ordered

Using the `instacart` data set, we can generate a plot showing the
number of items ordered in each aisle, limiting this to aisles with more
than 10,000 items ordered. This process involves counting the number of
distinct aisles and filtering the data to only include aisles in which
more than 10,000 items are ordered. We can then generate a scatter plot
using `ggplot`, with the aisles arranged in increasing order of number
of items ordered.

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(
    title = "Number of Items Ordered per Aisle", 
    x = "Aisle", 
    y = "Number of Items Ordered (n)") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1), 
        plot.title = element_text(hjust = 0.5))
```

![](p8105_hw3_hw2852_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

### Top 3 Most Popular Items per Aisle

The following table identifies the top 3 most popular items in the
`baking ingredients`, `dog food care` and `packaged vegetables fruits`
aisles, and enumerates the times each item is ordered.

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

| aisle                      | product_name                                  |    n | rank |
|:---------------------------|:----------------------------------------------|-----:|-----:|
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |

### Mean Hour of Purchases: Pink Lady Apples & Coffe Ice Cream

This final table displays the mean hour of the day at which the Pink
Lady Applies and Coffee Ice Cream products are ordered each day of the
week.

``` r
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

| product_name     |     0 |     1 |     2 |     3 |     4 |     5 |     6 |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

Based on the table generated above, we can conclude that Pink Lady
Apples are usually purchased earlier in the day than Coffee Ice Cream,
with the exception of Day 5.

# Problem 2

## 2.1 Accelerometer Data: Read, Tidy, Wrangle

We will begin by importing and cleaning the CSV file containing this
patient’s accelerometer data. This process involves data import,
cleaning variable names, and applying the `pivot_longer` function to
convert the data from wide to long format. A new `weekend_vs_weekday`
variable was generated to indicate whether the entry corresponds to a
weekend or a weekday.

``` r
accelerometer_data = 
  read_csv("./accel_data.csv") %>% 
  janitor::clean_names(.) %>% 
  mutate(weekend_vs_weekday = if_else(day != "Saturday" & day != "Sunday","weekday", "weekend")) %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "activity_time", 
    names_prefix = "activity_",
    names_transform = list(activity_time = as.integer),
    values_to = "activity_count")
```

    ## Rows: 35 Columns: 1443
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The tidied `accelerometer_data` data set contains **50400 rows** and **6
columns**. Each row in the data set corresponds to a single reading of
accelerometer activity. The variables in the data set include
identifiers of the week, day, and minute of the day at which the
accelerometer activity count is recorded. The newly created
`weekend_vs_weekday` variable also identifies whether the reading
corresponds to a weekend or a weekday. Accelerometer activity count data
is collected on **35 days** over **5 weeks**.

## 2.2 Total Daily Activity

Using the tidied accelerometer data generated in Part 2.1, we can
aggregate across daily minutes to create a total activity variable for
each of the 35 days of observation. We will first group the entries by
`day_id`, then apply the `summarise` function to generate a new variable
taking on the value of the sum of the activity counts associated with
the specific `day_id`.

``` r
accelerometer_data %>% 
  group_by(day_id) %>% 
  mutate(total_daily_activity = sum(activity_count)) %>% 
  summarise(day, total_daily_activity) %>% 
  distinct %>% 
  print(n = 35) %>% 
  knitr::kable()
```

    ## `summarise()` has grouped output by 'day_id'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 35 × 3
    ## # Groups:   day_id [35]
    ##    day_id day       total_daily_activity
    ##     <dbl> <chr>                    <dbl>
    ##  1      1 Friday                 480543.
    ##  2      2 Monday                  78828.
    ##  3      3 Saturday               376254 
    ##  4      4 Sunday                 631105 
    ##  5      5 Thursday               355924.
    ##  6      6 Tuesday                307094.
    ##  7      7 Wednesday              340115.
    ##  8      8 Friday                 568839 
    ##  9      9 Monday                 295431 
    ## 10     10 Saturday               607175 
    ## 11     11 Sunday                 422018 
    ## 12     12 Thursday               474048 
    ## 13     13 Tuesday                423245 
    ## 14     14 Wednesday              440962 
    ## 15     15 Friday                 467420 
    ## 16     16 Monday                 685910 
    ## 17     17 Saturday               382928 
    ## 18     18 Sunday                 467052 
    ## 19     19 Thursday               371230 
    ## 20     20 Tuesday                381507 
    ## 21     21 Wednesday              468869 
    ## 22     22 Friday                 154049 
    ## 23     23 Monday                 409450 
    ## 24     24 Saturday                 1440 
    ## 25     25 Sunday                 260617 
    ## 26     26 Thursday               340291 
    ## 27     27 Tuesday                319568 
    ## 28     28 Wednesday              434460 
    ## 29     29 Friday                 620860 
    ## 30     30 Monday                 389080 
    ## 31     31 Saturday                 1440 
    ## 32     32 Sunday                 138421 
    ## 33     33 Thursday               549658 
    ## 34     34 Tuesday                367824 
    ## 35     35 Wednesday              445366

| day_id | day       | total_daily_activity |
|-------:|:----------|---------------------:|
|      1 | Friday    |            480542.62 |
|      2 | Monday    |             78828.07 |
|      3 | Saturday  |            376254.00 |
|      4 | Sunday    |            631105.00 |
|      5 | Thursday  |            355923.64 |
|      6 | Tuesday   |            307094.24 |
|      7 | Wednesday |            340115.01 |
|      8 | Friday    |            568839.00 |
|      9 | Monday    |            295431.00 |
|     10 | Saturday  |            607175.00 |
|     11 | Sunday    |            422018.00 |
|     12 | Thursday  |            474048.00 |
|     13 | Tuesday   |            423245.00 |
|     14 | Wednesday |            440962.00 |
|     15 | Friday    |            467420.00 |
|     16 | Monday    |            685910.00 |
|     17 | Saturday  |            382928.00 |
|     18 | Sunday    |            467052.00 |
|     19 | Thursday  |            371230.00 |
|     20 | Tuesday   |            381507.00 |
|     21 | Wednesday |            468869.00 |
|     22 | Friday    |            154049.00 |
|     23 | Monday    |            409450.00 |
|     24 | Saturday  |              1440.00 |
|     25 | Sunday    |            260617.00 |
|     26 | Thursday  |            340291.00 |
|     27 | Tuesday   |            319568.00 |
|     28 | Wednesday |            434460.00 |
|     29 | Friday    |            620860.00 |
|     30 | Monday    |            389080.00 |
|     31 | Saturday  |              1440.00 |
|     32 | Sunday    |            138421.00 |
|     33 | Thursday  |            549658.00 |
|     34 | Tuesday   |            367824.00 |
|     35 | Wednesday |            445366.00 |

\*\*\* Data description

## 2.3 Plotting Accelerometer Daily Activity Count

We can apply the `ggplot` function to generate a single-panel plot
depicting the 24-hour activity time courses for each of the 35 days of
observation. In the line graph below, each day of observation’s
accelerometer activity count data is plotted against the corresponding
minute of the day at which the reading was recorded, with the different
colors delineating the day of the week.

``` r
accelerometer_data %>% 
  ggplot(aes(x = activity_time, y = activity_count, color = day)) +
  geom_line(aes(group = day_id)) +
  theme(
    legend.position = "bottom", 
    plot.title = element_text(hjust = 0.5)) +
  labs(
    title = "Plot of Accelerometer Daily Activity Count", 
    x = "Activity Time (Minute of Day)", 
    y = "Activity Count",
    color = "Day of Week") 
```

![](p8105_hw3_hw2852_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

\*\*\* Data description

# Problem 3

This problem uses `NY NOAA` data. This data set will be loaded through
the `p8105.datasets` library.

``` r
library(p8105.datasets)
data("ny_noaa")
```

## 3.1 NY NOAA Data: Tidying Data

We will first tidy the `ny_noaa` data set. This process involves
cleaning variable names, creating new `year`, `month` and `day`
variables from the existing `date` variable, and mutating year, month,
date, precipitation, maximum and minimum temperature variables to
appropriate (i.e., numeric) units).

``` r
ny_noaa_data = ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(col = date, into = c('year', 'month','day'), sep = '-') %>%
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day),
    prcp = prcp/10, 
    tmax = as.numeric(tmax) / 10,
    tmin = as.numeric(tmin) / 10
  )
```

## 3.2 Snowfall

Using the tidied `ny_noaa_data` data set, we can determine the most
commonly observed values of snowfall by first grouping the observations
by `snow`, then summarizing the number of observations for each `snow`
value, and arranging the output in descending order.

``` r
ny_noaa_data %>% 
  group_by(snow) %>% 
  summarise(snowfall_n_obs = n()) %>% 
  arrange(desc(snowfall_n_obs))
```

    ## # A tibble: 282 × 2
    ##     snow snowfall_n_obs
    ##    <int>          <int>
    ##  1     0        2008508
    ##  2    NA         381221
    ##  3    25          31022
    ##  4    13          23095
    ##  5    51          18274
    ##  6    76          10173
    ##  7     8           9962
    ##  8     5           9748
    ##  9    38           9197
    ## 10     3           8790
    ## # … with 272 more rows

## 3.3 Plotting Maximum Temperatures in January & July

To generate a 2-panel plot depicting the average maximum temperature in
January and July in each station across years.

``` r
ny_noaa_data %>%
  select(id, year, month, day, tmax) %>% 
  filter(month == 1 | month == 7) %>% 
  mutate(month = recode(month, 
                        '1' = 'January', 
                        '7' = 'July')) %>% 
  ggplot(aes(x = year, y = tmax)) +
  geom_point(aes(color = tmax)) +
  geom_smooth(se = FALSE, color = "yellow") +
  facet_grid(~month) +
  labs(
    title = "Maximum Temperatures in January vs. July (1981-2010)",
    x = "Year", 
    y = "Maximum Temperature (C)", 
    color = "Temperature (C)") +
  theme(
    plot.title = element_text(hjust = 0.5),
    strip.text = element_text(face = "bold"))
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

    ## Warning: Removed 190331 rows containing non-finite values (stat_smooth).

    ## Warning: Removed 190331 rows containing missing values (geom_point).

![](p8105_hw3_hw2852_files/figure-gfm/unnamed-chunk-12-1.png)<!-- -->

## 3.4 Plotting Maximum and Minimum Temperatures & Distribution of Snowfall

``` r
tmax_vs_tmin_p = 
ny_noaa_data %>% 
  select(tmax,tmin) %>% 
  drop_na(tmax, tmin) %>% 
  pivot_longer(
    tmax:tmin,
    names_to = "temp_observation", 
    values_to = "temp_measurement") %>%
  mutate(temp_observation = recode(temp_observation, 
                                   'tmax' = "Max Temperature",
                                   'tmin' = "Min Temperature")) %>% 
  ggplot(aes(x = temp_measurement, fill = temp_observation)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Maximum & Minimum Temperatures",
    x = "Temperature (C)", 
    y = "Density", 
    fill = "Observation") +
   theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5))

dist_snowfall_plot = 
  ny_noaa_data %>% 
  filter(0 < snow & snow < 100) %>% 
  group_by(year) %>% 
  ggplot(aes(x = snow, y = year, group = year, fill = year)) + 
  ggridges::geom_density_ridges() + 
  viridis::scale_fill_viridis() +
  labs(
    title = "Distribution of Snowfall",
    x = "Snowfall (mm)", 
    y = "Density", 
    fill = "year") +
   theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5))   

tmax_vs_tmin_p + dist_snowfall_plot
```

    ## Picking joint bandwidth of 3.76

![](p8105_hw3_hw2852_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->
