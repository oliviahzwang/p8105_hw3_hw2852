---
title: "P8105 Data Science I Homework 3"
author: Olivia Wang (hw2852)
output: github_document
date: "2022-10-15"
---

In preparation for the problems below, we will load the following libraries: 

```{r load_libraries}
library(tidyverse)
library(readxl)
library(dplyr)
```

# Problem 1

This problem uses the `Instacart` data. This data set will be loaded through the `p8105.datasets` library. 

```{r}
library(p8105.datasets)
data("instacart")
```

## 1.1 Description of `Instacart` Data 


## 1.2 Analysis of `Instacart` Data

### Aisles

We can enumerate the number of aisles by applying the `group_by` function to identify the number of unique `aisle_id` variable values. The number of rows generated in the output would be the number of aisles in the data set. Building upon the results generated from the `group_by` function, we may determine the aisles from which the most items were ordered. This process involves generating a summary of the number of times each `aisle_id` appears in these data, then arranging the aisles in decreasing order of the number of times it appears. 

```{r}
instacart %>%
  group_by(aisle_id) %>% 
  summarise(items_ordered = n()) %>% 
  arrange(desc(items_ordered))
```

There are __134 aisles__ in the `Instacart` data set. Of the 134 aisles, the following are the aisles from which the most items are ordered:

Aisle Number   Number of Items Sold
-------------  --------------------
__83__         150,609
__24__         150,473
__123__        78,493
__120__        55,240
__21__         41,699

### Plotting Aisle vs. Items Ordered

```{r}
instacart %>% 
  group_by(aisle_id) %>% 
  mutate(items_ordered = n()) %>% 
  filter(items_ordered > 10000) %>% 
  ggplot(aes(x = aisle_id)) + 
  geom_histogram(color = "black", fill = "lightblue") + 
  labs(title = "Plot of Aisle by Numbers of Items Sold", x = "Aisle ID", y = "Number of Items Ordered")
```

# Problem 2

## 2.1 Accelerometer Data: Read, Tidy, Wrangle

We will begin by importing and cleaning the CSV file containing this patient's accelerometer data. This process involves data import, cleaning variable names, and applying the `pivot_longer` function to convert the data from wide to long format. A new `weekend_vs_weekday` variable was generated to indicate whether the entry corresponds to a weekend or a weekday.

```{r}
accelerometer_data = 
  read_csv("./accel_data.csv") %>% 
  janitor::clean_names(.) %>% 
  mutate(weekend_vs_weekday = if_else(day != "Saturday" & day != "Sunday","weekday", "weekend")) %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "activity_time", 
    names_prefix = "activity_",
    names_transform = list(activity_time = as.integer),
    values_to = "activity_count")
```

*** Data description 

## 2.2 Total Daily Activity

Using the tidied accelerometer data generated in Part 2.1, we can aggregate across daily minutes to create a total activity variable for each of the 35 days of observation. We will first group the entries by `day_id`, then apply the `summarise` function to generate a new variable taking on the value of the sum of the activity counts associated with the specific `day_id`. 

```{r}
accelerometer_data %>% 
  group_by(day_id) %>% 
  summarise(total_daily_activity = sum(activity_count)) %>% 
  print(n = 35)
```

*** Data description

## 2.3 Plotting Daily Inspection Activity 

```{r}
accelerometer_data %>% 
  ggplot(aes(x = activity_time, y = activity_count, color = day)) +
  geom_point() +
  theme(
    legend.position = "bottom", 
    plot.title = element_text(hjust = 0.5)) +
  labs(
    title = "Plot of Daily Inspection Activity", 
    x = "Activity Time (Minute of Day)", 
    y = "Activity Count",
    color = "Day of Week") 
```






